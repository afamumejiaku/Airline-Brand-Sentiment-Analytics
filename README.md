# âœˆï¸ Airline Brand Sentiment Analytics
## FTA-LSTM vs Bipartite Graph Neural Networks: A Comparative Study

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

> **End-to-end social analytics pipeline** comparing American Airlines vs Southwest Airlines brand sentiment using deep learning approaches.

<p align="center">
  <img src="assets/model_comparison.png" alt="Model Comparison Results" width="800"/>
</p>

---

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [Key Results](#-key-results)
- [Architecture](#-architecture)
- [Dataset](#-dataset)
- [Models](#-models)
- [Installation](#-installation)
- [Usage](#-usage)
- [Results & Analysis](#-results--analysis)
- [Business Insights](#-business-insights)
- [Future Work](#-future-work)
- [Author](#-author)

---

## ğŸ¯ Overview

### The Business Problem

> *"How do customers really perceive our airline brand, and how does sentiment spread through online communities?"*

This project transforms an ambiguous business question into measurable analytical objectives:

| Business Question | Analytical Objective | Method |
|-------------------|---------------------|--------|
| Overall brand health? | Sentiment Classification | FTA-LSTM / Bipartite GNN |
| What drives opinions? | Aspect-Based Sentiment | Attention Weight Analysis |
| Who influences perception? | Network Influence Analysis | Graph Centrality Metrics |
| Can we predict shifts? | Temporal Forecasting | Time Attention Mechanism |

### Research Question

**Can Frequency-Time Attention LSTM (FTA-LSTM) outperform Bipartite Graph Neural Networks for sentiment classification on social media text, and what are the trade-offs?**

---

## ğŸ† Key Results

### Model Performance Comparison

| Model | Accuracy | F1 Score | ROC-AUC | Inference Time |
|-------|----------|----------|---------|----------------|
| VADER (Baseline) | 0.682 | 0.651 | 0.724 | <1ms |
| TF-IDF + Logistic Regression | 0.754 | 0.731 | 0.812 | <1ms |
| TF-IDF + Random Forest | 0.773 | 0.752 | 0.834 | <1ms |
| **FTA-LSTM** | **0.847** | **0.829** | **0.901** | 5ms |
| Bipartite GNN | 0.821 | 0.803 | 0.878 | 8ms |
| Ensemble (FTA + GNN) | **0.862** | **0.844** | **0.918** | 13ms |

### Key Findings

âœ… **FTA-LSTM outperforms Bipartite GNN by 2.6% F1 score** (statistically significant, p < 0.05)

âœ… **Attention mechanisms provide interpretability** â€” identified key sentiment-bearing phrases

âœ… **Graph structure captures community patterns** â€” useful for influence analysis

âœ… **Ensemble achieves best overall performance** â€” combining sequential and structural insights

---

## ğŸ—ï¸ Architecture

### System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         DATA COLLECTION LAYER                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Twitter API â”€â”€â”€â”€â”€â–º News API â”€â”€â”€â”€â”€â–º Skytrax â”€â”€â”€â”€â”€â–º Google News         â”‚
â”‚    (14K tweets)    (500 articles)  (800 reviews)   (100 headlines)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         PREPROCESSING LAYER                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Text Cleaning â”€â”€â–º Tokenization â”€â”€â–º Embedding â”€â”€â–º Graph Construction   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â–¼                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       FTA-LSTM             â”‚   â”‚    BIPARTITE GNN           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Embedding Layer          â”‚   â”‚ â€¢ User-Post Graph          â”‚
â”‚ â€¢ Frequency Attention      â”‚   â”‚ â€¢ GraphSAGE Convolutions   â”‚
â”‚ â€¢ Bidirectional LSTM       â”‚   â”‚ â€¢ Message Passing          â”‚
â”‚ â€¢ Time Attention           â”‚   â”‚ â€¢ Node Classification      â”‚
â”‚ â€¢ Dense Classifier         â”‚   â”‚ â€¢ Community Detection      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚                               â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         EVALUATION LAYER                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  5-Fold CV â”€â”€â–º Statistical Tests â”€â”€â–º Attention Viz â”€â”€â–º Power BI        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### FTA-LSTM Architecture

```
Input Sequence
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Embedding Layer â”‚ (300-dim GloVe)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frequency     â”‚ â”€â”€â–º Attention Weights (Word Importance)
â”‚   Attention     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Bi-LSTM Layers  â”‚ (128 units Ã— 2 layers)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Time        â”‚ â”€â”€â–º Attention Weights (Position Importance)
â”‚   Attention     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼# Airline-Brand-Sentiment-Analytics
Deep learning sentiment analysis comparing FTA-LSTM vs Graph Neural Networks on 16K+ airline reviews. Multi-source data pipeline (Twitter, NewsAPI, Skytrax). 

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Classification  â”‚ â”€â”€â–º Positive / Neutral / Negative
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Dataset

### Multi-Source Data Collection

| Source | Records | Type | Sentiment Labels |
|--------|---------|------|------------------|
| **Twitter (Kaggle)** | 14,640 | Tweets | Human-annotated |
| **NewsAPI** | 523 | News Articles | VADER-estimated |
| **Skytrax** | 847 | Airline Reviews | Rating-derived |
| **Google News** | 112 | Headlines | VADER-estimated |
| **Total** | **16,122** | - | - |

### Sentiment Distribution

```
Negative  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  62.3% (10,048)
Neutral   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      21.2% (3,419)
Positive  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                            16.5% (2,655)
```

### Airline Distribution

```
American Airlines   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  52.1% (8,402)
Southwest Airlines  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ      47.9% (7,720)
```

### Aspect Distribution (from Negative Tweets)

| Aspect | Count | % of Negative |
|--------|-------|---------------|
| Customer Service | 2,910 | 29.0% |
| Late Flight | 1,665 | 16.6% |
| Cancelled Flight | 966 | 9.6% |
| Lost Luggage | 724 | 7.2% |
| Bad Flight | 580 | 5.8% |
| Flight Booking | 529 | 5.3% |

---

## ğŸ§  Models

### 1. FTA-LSTM (Frequency-Time Attention LSTM)

**Key Innovation:** Dual attention mechanism capturing both *what* words matter and *where* they appear in the sequence.

```python
class FTALTM(nn.Module):
    def __init__(self, vocab_size, embedding_dim=300, hidden_dim=128):
        self.embedding = nn.Embedding(vocab_size, embedding_dim)
        self.freq_attention = FrequencyAttention(embedding_dim)
        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True)
        self.time_attention = TimeAttention(hidden_dim * 2)
        self.classifier = nn.Linear(hidden_dim * 2, 3)
```

**Hyperparameters:**
- Embedding: 300-dim (GloVe pre-trained)
- LSTM: 128 hidden units, 2 layers, bidirectional
- Dropout: 0.3
- Optimizer: Adam (lr=0.001)
- Batch size: 64

### 2. Bipartite Graph Neural Network

**Key Innovation:** Models user-post relationships to capture community-level sentiment patterns.

```python
# Graph Structure
Users â”€â”€authoredâ”€â”€â–º Posts
Users â”€â”€commentedâ”€â”€â–º Posts
Posts â”€â”€similarâ”€â”€â–º Posts (cosine similarity > 0.3)
```

**Architecture:**
- Node features: TF-IDF embeddings (128-dim)
- GNN layers: 2Ã— GraphSAGE
- Aggregation: Mean pooling
- Classification: MLP head

---

## ğŸš€ Installation

### Prerequisites

- Python 3.10+
- CUDA 11.8+ (optional, for GPU acceleration)

### Setup

```bash
# Clone repository
git clone https://github.com/yourusername/airline-sentiment-analytics.git
cd airline-sentiment-analytics

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Download NLTK data
python -c "import nltk; nltk.download('punkt'); nltk.download('stopwords')"
```

### Dependencies

```txt
torch>=2.0.0
torch-geometric>=2.3.0
pandas>=2.0.0
scikit-learn>=1.2.0
vaderSentiment>=3.3.2
beautifulsoup4>=4.12.0
requests>=2.31.0
matplotlib>=3.7.0
seaborn>=0.12.0# Airline-Brand-Sentiment-Analytics
Deep learning sentiment analysis comparing FTA-LSTM vs Graph Neural Networks on 16K+ airline reviews. Multi-source data pipeline (Twitter, NewsAPI, Skytrax). 

tqdm>=4.65.0
```

---

## ğŸ’» Usage

### Quick Start

```bash
# 1. Download Kaggle dataset
# Go to: kaggle.com/datasets/crowdflower/twitter-airline-sentiment
# Download and extract Tweets.csv to project root

# 2. Collect all data sources
python collect_all_data.py --newsapi_key YOUR_API_KEY

# 3. Run model comparison
python compare_models.py

# 4. View results
cat comparison_results.json
```

### Individual Components

```bash
# Import Kaggle Twitter data only
python kaggle_airline_sentiment.py

# Collect news articles
python news_api_collector.py --api_key YOUR_KEY --days 30

# Scrape airline reviews
python airline_review_scraper.py

# Train FTA-LSTM only
python fta_lstm.py

# Train Bipartite GNN only
python bipartite_gnn.py
```

### Using as a Library

```python
from fta_lstm import FTALTM, TextPreprocessor, train_model, evaluate_model

# Preprocess text
preprocessor = TextPreprocessor(max_vocab=20000, max_length=128)
X = preprocessor.fit_transform(texts)

# Initialize model
model = FTALTM(
    vocab_size=len(preprocessor.word2idx),
    embedding_dim=300,
    hidden_dim=128,
    num_classes=3
)

# Train
history = train_model(model, train_loader, val_loader, epochs=15)

# Evaluate
results = evaluate_model(model, test_loader)
print(f"F1 Score: {results['f1_macro']:.4f}")

# Get attention weights for interpretability
attention = model.get_attention_weights(sample_text)
```

---

## ğŸ“ˆ Results & Analysis

### Confusion Matrices

<p align="center">
  <img src="assets/confusion_matrix_fta_lstm.png" alt="FTA-LSTM Confusion Matrix" width="400"/>
  <img src="assets/confusion_matrix_gnn.png" alt="Bipartite GNN Confusion Matrix" width="400"/>
</p>

### Attention Visualization

**Example: Negative Sentiment Tweet**

```
"@AmericanAir worst customer service ever! Been waiting 3 hours for help. Never flying again!"

Frequency Attention (word importance):
  worst        â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  0.89
  waiting      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       0.71
  Never        â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        0.68
  hours        â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ          0.58
  help         â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ              0.42
  
Time Attention (position importance):
  Position 3-5 (worst customer service) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  0.82
  Position 12-14 (Never flying again)   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    0.71
```

### Learning Curves

<p align="center">
  <img src="assets/learning_curves.png" alt="Learning Curves" width="600"/>
</p>

### Statistical Significance

| Comparison | Test | Statistic | p-value | Significant? |
|------------|------|-----------|---------|--------------|
| FTA-LSTM vs TF-IDF+LR | Paired t-test | 4.23 | 0.003 | âœ… Yes |
| FTA-LSTM vs Bipartite GNN | Paired t-test | 2.18 | 0.042 | âœ… Yes |
| FTA-LSTM vs Random Forest | McNemar's | 12.4 | 0.001 | âœ… Yes |

---

## ğŸ’¼ Business Insights

### Brand Sentiment Comparison

| Metric | American Airlines | Southwest Airlines |
|--------|-------------------|-------------------|
| Overall Sentiment | -0.234 | -0.089 |
| Positive Rate | 14.2% | 19.1% |
| Negative Rate | 65.8% | 58.3% |
| Top Complaint | Customer Service (32%) | Delays (28%) |
| Top Praise | Loyalty Program (41%) | Pricing (38%) |

### Aspect-Level Analysis

```
                    American    Southwest
                    â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”€â”€â”€â”€â”€â”€â”€â”€â”€
Customer Service    â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘
Pricing             â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘
Delays              â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘   â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘
Baggage             â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘
Loyalty Program     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘
WiFi/Entertainment  â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘   â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘

(â–ˆ = Positive sentiment, â–‘ = Negative sentiment)
```

### Actionable Recommendations

1. **American Airlines:** Prioritize customer service training â€” 32% of negative mentions cite service issues

2. **Southwest Airlines:** Address WiFi reliability â€” emerging complaint category with high engagement

3. **Both Airlines:** Monitor loyalty program sentiment â€” high-value customers are vocal advocates

4. **Marketing Opportunity:** Southwest's "bags fly free" messaging drives 38% of positive mentions

---

## ğŸ”® Future Work

- [ ] **Real-time streaming pipeline** â€” Process live Twitter/news feeds
- [ ] **Transformer integration** â€” Replace LSTM with BERT/RoBERTa encoders
- [ ] **Multi-task learning** â€” Joint sentiment + aspect classification
- [ ] **Explainable AI dashboard** â€” Interactive attention visualization
- [ ] **Competitor expansion** â€” Add Delta, United, JetBlue analysis
- [ ] **Causal inference** â€” Impact of events on sentiment (strikes, incidents)

---

## ğŸ“ Project Structure

```
airline-sentiment-analytics/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Raw downloaded data
â”‚   â”œâ”€â”€ processed/              # Cleaned data
â”‚   â””â”€â”€ airline_sentiment.db    # SQLite database
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ fta_lstm.py             # FTA-LSTM implementation
â”‚   â”œâ”€â”€ bipartite_gnn.py        # Bipartite GNN implementation
â”‚   â””â”€â”€ checkpoints/            # Saved model weights
â”‚
â”œâ”€â”€ collectors/
â”‚   â”œâ”€â”€ kaggle_airline_sentiment.py
â”‚   â”œâ”€â”€ news_api_collector.py
â”‚   â””â”€â”€ airline_review_scraper.py
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_model_training.ipynb
â”‚   â””â”€â”€ 03_results_analysis.ipynb
â”‚
â”œâ”€â”€ assets/                     # Images for README
â”œâ”€â”€ collect_all_data.py         # Master collection script
â”œâ”€â”€ compare_models.py           # Model comparison pipeline
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ Technical Skills Demonstrated

| Category | Technologies |
|----------|-------------|
| **Deep Learning** | PyTorch, LSTM, Attention Mechanisms, GNN |
| **NLP** | Tokenization, Embeddings, Sentiment Analysis, VADER |
| **Graph ML** | PyTorch Geometric, GraphSAGE, Node Classification |
| **Data Engineering** | Web Scraping, API Integration, ETL Pipelines |
| **Databases** | SQLite, Schema Design, Query Optimization |
| **Visualization** | Matplotlib, Seaborn, Power BI |
| **MLOps** | Cross-Validation, Hyperparameter Tuning, Model Comparison |
| **Statistics** | Hypothesis Testing, McNemar's Test, Confidence Intervals |

---

## ğŸ“– References

1. Vaswani et al. (2017). "Attention Is All You Need"
2. Hamilton et al. (2017). "Inductive Representation Learning on Large Graphs"
3. Hutto & Gilbert (2014). "VADER: A Parsimonious Rule-based Model for Sentiment Analysis"

---

## ğŸ‘¤ Author

**Afamefuna Umejiaku**
- afamumejiaku@gmail.com

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- [Kaggle](https://www.kaggle.com/) for the Twitter Airline Sentiment dataset
- [NewsAPI](https://newsapi.org/) for news article access
- [Skytrax](https://www.airlinequality.com/) for airline review data

---

<p align="center">
  <i>Built with â¤ï¸ for demonstrating end-to-end ML pipeline development</i>
</p>
